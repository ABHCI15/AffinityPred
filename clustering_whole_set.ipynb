{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567b406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nroethler/miniconda3/envs/gen_ca/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import esm\n",
    "from descriptastorus.descriptors import rdNormalizedDescriptors\n",
    "import warnings\n",
    "# import faiss\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Enable pandas progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "# Parameters\n",
    "RANDOM_STATE = 5\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c052d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Target sample size: 49,511\n",
      "Available negatives: 12,201,748\n",
      "Sampling ratio: 0.004\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load datasets and get target sample size\n",
    "print(\"Loading datasets...\")\n",
    "df_complete = pd.read_csv(\"./datasets/cysdb_complete_with_sequences.csv\").dropna(subset=['SMILES', 'Sequence'])\n",
    "\n",
    "\n",
    "# Set target sample size to match positives\n",
    "NUM_SAMPLES = len(df_complete[df_complete['Activity'] == 1])\n",
    "print(f\"Target sample size: {NUM_SAMPLES:,}\")\n",
    "print(f\"Available negatives: {len(df_complete[df_complete['Activity'] == 0]):,}\")\n",
    "print(f\"Sampling ratio: {NUM_SAMPLES / len(df_complete[df_complete['Activity'] == 0]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c31761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up ESM-C model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 22857.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique proteins to embed: 9,446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding proteins: 100%|██████████| 9446/9446 [06:08<00:00, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating protein embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from esm.models.esmc import ESMC\n",
    "from esm.sdk.api import (\n",
    "    ESM3InferenceClient,\n",
    "    ESMProtein,\n",
    "    LogitsConfig,\n",
    "    LogitsOutput,\n",
    "    ProteinType,\n",
    ")\n",
    "EMBEDDING_CONFIG = LogitsConfig(\n",
    "    sequence=True, return_embeddings=True, return_hidden_states=False\n",
    ")\n",
    "# Cell 3: ESM-C protein embeddings + RDKit normalized descriptors\n",
    "print(\"Setting up ESM-C model...\")\n",
    "client = ESMC.from_pretrained(\"esmc_600m\").to(\"cuda\")\n",
    "def embed_sequence(model: ESM3InferenceClient, sequence: str) -> torch.Tensor:\n",
    "    protein = ESMProtein(sequence=sequence)\n",
    "    protein_tensor = model.encode(protein)\n",
    "    output = model.logits(protein_tensor, EMBEDDING_CONFIG)\n",
    "    # output.embeddings: shape [1, seq_len, 1152]\n",
    "    mean_embedding = output.embeddings.mean(dim=1).squeeze(0).detach().cpu().numpy()  # shape [1152]\n",
    "    return mean_embedding\n",
    "\n",
    "# Get unique proteins\n",
    "proteins_unique = df_complete['Sequence'].unique()\n",
    "print(f\"Unique proteins to embed: {len(proteins_unique):,}\")\n",
    "\n",
    "protein_embed_dict = {}\n",
    "\n",
    "for sequence in tqdm(proteins_unique, total=len(proteins_unique), desc=\"Embedding proteins\"):\n",
    "    if sequence not in protein_embed_dict:\n",
    "        try:\n",
    "            embedding = embed_sequence(client, sequence)\n",
    "            protein_embed_dict[sequence] = embedding\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding {sequence}: {e}\")\n",
    "\n",
    "\n",
    "print(\"Generating protein embeddings...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b714ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# Clear memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2153763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing molecular descriptors...\n",
      "Unique molecules: 352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit descriptors: 100%|██████████| 352/352 [00:04<00:00, 71.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated features for 352 molecules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: RDKit molecular descriptors\n",
    "print(\"Computing molecular descriptors...\")\n",
    "gen = rdNormalizedDescriptors.RDKit2DNormalized()\n",
    "\n",
    "# Get unique molecules\n",
    "unique_molecules = df_complete['SMILES'].unique()\n",
    "print(f\"Unique molecules: {len(unique_molecules):,}\")\n",
    "\n",
    "# Storage for molecular features\n",
    "molecule_features = {}\n",
    "\n",
    "# Process molecules\n",
    "for smiles in tqdm(unique_molecules, desc=\"RDKit descriptors\"):\n",
    "    try:\n",
    "        desc = gen.process(smiles=smiles)\n",
    "        if desc is not None and len(desc) > 1:\n",
    "            molecule_features[smiles] = np.array(desc[1:], dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {smiles}: {e}\")\n",
    "\n",
    "print(f\"Generated features for {len(molecule_features)} molecules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df1b62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more memory efficient storage\n",
    "df_complete['concatenated_features'] = df_complete.apply(\n",
    "    lambda row: np.concatenate((protein_embed_dict[row['Sequence']], molecule_features[row['SMILES']])), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d0892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (12251259, 1352)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare data for faiss (float32, contiguous)\n",
    "features = np.stack(df_complete['concatenated_features'].values).astype('float32')\n",
    "features = np.ascontiguousarray(features)\n",
    "shape = features.shape\n",
    "print(f\"Features shape: {shape}\")\n",
    "features.tofile(\"./datasets/features.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb86e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.memmap(\"./datasets/features.npy\", dtype='float32', mode='r', shape=(12251259, 1352))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe6b427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# Clear memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ecd649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss \n",
    "faiss.get_num_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb15c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 12251259, Dimension: 1352\n",
      "Clustering with faiss-gpu...\n",
      "Using 300 clusters\n",
      "Clustering 12251259 points in 1352D to 300 clusters, redo 1 times, 50 iterations\n",
      "  Preprocessing in 7.11 s\n",
      "  Iteration 49 (246.65 s, search 126.31 s): objective=6.74866e+08 imbalance=299.999 nsplit=298       \n",
      "Cluster assignment complete. Cluster counts:\n",
      "  Cluster 0: 286 samples\n",
      "  Cluster 1: 23 samples\n",
      "  Cluster 2: 139 samples\n",
      "  Cluster 3: 214 samples\n",
      "  Cluster 4: 332 samples\n",
      "  Cluster 5: 70 samples\n",
      "  Cluster 7: 262 samples\n",
      "  Cluster 8: 400 samples\n",
      "  Cluster 9: 118 samples\n",
      "  Cluster 10: 70 samples\n",
      "  Cluster 11: 283 samples\n",
      "  Cluster 12: 286 samples\n",
      "  Cluster 13: 46 samples\n",
      "  Cluster 14: 115 samples\n",
      "  Cluster 15: 216 samples\n",
      "  Cluster 16: 192 samples\n",
      "  Cluster 17: 94 samples\n",
      "  Cluster 18: 115 samples\n",
      "  Cluster 19: 191 samples\n",
      "  Cluster 20: 238 samples\n",
      "  Cluster 21: 139 samples\n",
      "  Cluster 22: 323 samples\n",
      "  Cluster 23: 286 samples\n",
      "  Cluster 24: 213 samples\n",
      "  Cluster 25: 47 samples\n",
      "  Cluster 26: 92 samples\n",
      "  Cluster 27: 263 samples\n",
      "  Cluster 28: 308 samples\n",
      "  Cluster 29: 47 samples\n",
      "  Cluster 30: 416 samples\n",
      "  Cluster 31: 261 samples\n",
      "  Cluster 32: 214 samples\n",
      "  Cluster 33: 230 samples\n",
      "  Cluster 34: 93 samples\n",
      "  Cluster 35: 142 samples\n",
      "  Cluster 36: 169 samples\n",
      "  Cluster 37: 322 samples\n",
      "  Cluster 38: 162 samples\n",
      "  Cluster 39: 263 samples\n",
      "  Cluster 41: 185 samples\n",
      "  Cluster 42: 47 samples\n",
      "  Cluster 43: 189 samples\n",
      "  Cluster 44: 145 samples\n",
      "  Cluster 45: 70 samples\n",
      "  Cluster 46: 72 samples\n",
      "  Cluster 47: 425 samples\n",
      "  Cluster 48: 260 samples\n",
      "  Cluster 49: 282 samples\n",
      "  Cluster 50: 70 samples\n",
      "  Cluster 51: 214 samples\n",
      "  Cluster 52: 307 samples\n",
      "  Cluster 53: 325 samples\n",
      "  Cluster 54: 140 samples\n",
      "  Cluster 55: 237 samples\n",
      "  Cluster 56: 190 samples\n",
      "  Cluster 57: 69 samples\n",
      "  Cluster 58: 117 samples\n",
      "  Cluster 59: 216 samples\n",
      "  Cluster 60: 212 samples\n",
      "  Cluster 61: 165 samples\n",
      "  Cluster 62: 232 samples\n",
      "  Cluster 63: 192 samples\n",
      "  Cluster 64: 167 samples\n",
      "  Cluster 65: 255 samples\n",
      "  Cluster 66: 139 samples\n",
      "  Cluster 67: 377 samples\n",
      "  Cluster 68: 259 samples\n",
      "  Cluster 69: 119 samples\n",
      "  Cluster 70: 162 samples\n",
      "  Cluster 71: 285 samples\n",
      "  Cluster 72: 258 samples\n",
      "  Cluster 73: 141 samples\n",
      "  Cluster 74: 139 samples\n",
      "  Cluster 75: 385 samples\n",
      "  Cluster 76: 120 samples\n",
      "  Cluster 77: 188 samples\n",
      "  Cluster 78: 115 samples\n",
      "  Cluster 79: 241 samples\n",
      "  Cluster 80: 400 samples\n",
      "  Cluster 81: 306 samples\n",
      "  Cluster 82: 118 samples\n",
      "  Cluster 83: 360 samples\n",
      "  Cluster 84: 167 samples\n",
      "  Cluster 85: 283 samples\n",
      "  Cluster 86: 140 samples\n",
      "  Cluster 87: 402 samples\n",
      "  Cluster 88: 212 samples\n",
      "  Cluster 89: 95 samples\n",
      "  Cluster 90: 115 samples\n",
      "  Cluster 91: 217 samples\n",
      "  Cluster 92: 541 samples\n",
      "  Cluster 93: 71 samples\n",
      "  Cluster 95: 192 samples\n",
      "  Cluster 96: 262 samples\n",
      "  Cluster 97: 118 samples\n",
      "  Cluster 98: 255 samples\n",
      "  Cluster 99: 238 samples\n",
      "  Cluster 100: 167 samples\n",
      "  Cluster 101: 190 samples\n",
      "  Cluster 102: 278 samples\n",
      "  Cluster 103: 261 samples\n",
      "  Cluster 104: 192 samples\n",
      "  Cluster 105: 565 samples\n",
      "  Cluster 106: 69 samples\n",
      "  Cluster 107: 169 samples\n",
      "  Cluster 108: 312 samples\n",
      "  Cluster 109: 306 samples\n",
      "  Cluster 110: 488 samples\n",
      "  Cluster 111: 332 samples\n",
      "  Cluster 112: 265 samples\n",
      "  Cluster 113: 141 samples\n",
      "  Cluster 114: 92 samples\n",
      "  Cluster 115: 239 samples\n",
      "  Cluster 116: 264 samples\n",
      "  Cluster 117: 398 samples\n",
      "  Cluster 118: 118 samples\n",
      "  Cluster 119: 146 samples\n",
      "  Cluster 120: 403 samples\n",
      "  Cluster 121: 165 samples\n",
      "  Cluster 122: 140 samples\n",
      "  Cluster 123: 215 samples\n",
      "  Cluster 124: 450 samples\n",
      "  Cluster 125: 96 samples\n",
      "  Cluster 126: 190 samples\n",
      "  Cluster 127: 192 samples\n",
      "  Cluster 128: 540 samples\n",
      "  Cluster 129: 97 samples\n",
      "  Cluster 130: 401 samples\n",
      "  Cluster 131: 455 samples\n",
      "  Cluster 132: 170 samples\n",
      "  Cluster 133: 285 samples\n",
      "  Cluster 134: 93 samples\n",
      "  Cluster 135: 358 samples\n",
      "  Cluster 136: 265 samples\n",
      "  Cluster 137: 524 samples\n",
      "  Cluster 138: 262 samples\n",
      "  Cluster 139: 214 samples\n",
      "  Cluster 140: 289 samples\n",
      "  Cluster 141: 237 samples\n",
      "  Cluster 142: 143 samples\n",
      "  Cluster 143: 213 samples\n",
      "  Cluster 144: 311 samples\n",
      "  Cluster 145: 141 samples\n",
      "  Cluster 146: 281 samples\n",
      "  Cluster 147: 352 samples\n",
      "  Cluster 148: 431 samples\n",
      "  Cluster 149: 71 samples\n",
      "  Cluster 150: 495 samples\n",
      "  Cluster 151: 403 samples\n",
      "  Cluster 152: 380 samples\n",
      "  Cluster 153: 120 samples\n",
      "  Cluster 154: 236 samples\n",
      "  Cluster 155: 402 samples\n",
      "  Cluster 156: 310 samples\n",
      "  Cluster 157: 191 samples\n",
      "  Cluster 158: 258 samples\n",
      "  Cluster 159: 283 samples\n",
      "  Cluster 160: 265 samples\n",
      "  Cluster 161: 142 samples\n",
      "  Cluster 162: 333 samples\n",
      "  Cluster 163: 144 samples\n",
      "  Cluster 164: 357 samples\n",
      "  Cluster 165: 190 samples\n",
      "  Cluster 166: 307 samples\n",
      "  Cluster 167: 282 samples\n",
      "  Cluster 168: 288 samples\n",
      "  Cluster 169: 257 samples\n",
      "  Cluster 170: 237 samples\n",
      "  Cluster 171: 446 samples\n",
      "  Cluster 172: 264 samples\n",
      "  Cluster 173: 189 samples\n",
      "  Cluster 174: 163 samples\n",
      "  Cluster 175: 214 samples\n",
      "  Cluster 176: 474 samples\n",
      "  Cluster 177: 72 samples\n",
      "  Cluster 178: 117 samples\n",
      "  Cluster 179: 236 samples\n",
      "  Cluster 180: 379 samples\n",
      "  Cluster 181: 120 samples\n",
      "  Cluster 182: 70 samples\n",
      "  Cluster 183: 188 samples\n",
      "  Cluster 184: 193 samples\n",
      "  Cluster 185: 1270 samples\n",
      "  Cluster 186: 141 samples\n",
      "  Cluster 187: 550 samples\n",
      "  Cluster 188: 309 samples\n",
      "  Cluster 189: 233 samples\n",
      "  Cluster 190: 141 samples\n",
      "  Cluster 191: 405 samples\n",
      "  Cluster 192: 193 samples\n",
      "  Cluster 193: 238 samples\n",
      "  Cluster 194: 642 samples\n",
      "  Cluster 195: 214 samples\n",
      "  Cluster 196: 354 samples\n",
      "  Cluster 197: 189 samples\n",
      "  Cluster 198: 141 samples\n",
      "  Cluster 199: 237 samples\n",
      "  Cluster 200: 12173178 samples\n",
      "  Cluster 201: 258 samples\n",
      "  Cluster 202: 143 samples\n",
      "  Cluster 203: 569 samples\n",
      "  Cluster 204: 426 samples\n",
      "  Cluster 205: 902 samples\n",
      "  Cluster 206: 474 samples\n",
      "  Cluster 207: 334 samples\n",
      "  Cluster 208: 379 samples\n",
      "  Cluster 209: 165 samples\n",
      "  Cluster 210: 117 samples\n",
      "  Cluster 211: 384 samples\n",
      "  Cluster 212: 308 samples\n",
      "  Cluster 213: 187 samples\n",
      "  Cluster 214: 279 samples\n",
      "  Cluster 215: 193 samples\n",
      "  Cluster 216: 289 samples\n",
      "  Cluster 217: 71 samples\n",
      "  Cluster 218: 304 samples\n",
      "  Cluster 219: 308 samples\n",
      "  Cluster 220: 191 samples\n",
      "  Cluster 221: 235 samples\n",
      "  Cluster 222: 119 samples\n",
      "  Cluster 223: 520 samples\n",
      "  Cluster 224: 308 samples\n",
      "  Cluster 225: 141 samples\n",
      "  Cluster 226: 468 samples\n",
      "  Cluster 227: 194 samples\n",
      "  Cluster 228: 284 samples\n",
      "  Cluster 229: 403 samples\n",
      "  Cluster 230: 191 samples\n",
      "  Cluster 231: 288 samples\n",
      "  Cluster 232: 262 samples\n",
      "  Cluster 233: 379 samples\n",
      "  Cluster 234: 167 samples\n",
      "  Cluster 235: 357 samples\n",
      "  Cluster 236: 169 samples\n",
      "  Cluster 237: 400 samples\n",
      "  Cluster 238: 165 samples\n",
      "  Cluster 239: 309 samples\n",
      "  Cluster 240: 240 samples\n",
      "  Cluster 241: 214 samples\n",
      "  Cluster 242: 379 samples\n",
      "  Cluster 243: 193 samples\n",
      "  Cluster 244: 311 samples\n",
      "  Cluster 245: 95 samples\n",
      "  Cluster 246: 73 samples\n",
      "  Cluster 247: 474 samples\n",
      "  Cluster 248: 167 samples\n",
      "  Cluster 249: 234 samples\n",
      "  Cluster 250: 142 samples\n",
      "  Cluster 251: 528 samples\n",
      "  Cluster 252: 147 samples\n",
      "  Cluster 253: 281 samples\n",
      "  Cluster 254: 215 samples\n",
      "  Cluster 255: 240 samples\n",
      "  Cluster 256: 477 samples\n",
      "  Cluster 257: 214 samples\n",
      "  Cluster 258: 166 samples\n",
      "  Cluster 259: 264 samples\n",
      "  Cluster 260: 338 samples\n",
      "  Cluster 261: 141 samples\n",
      "  Cluster 262: 117 samples\n",
      "  Cluster 263: 337 samples\n",
      "  Cluster 264: 1038 samples\n",
      "  Cluster 265: 281 samples\n",
      "  Cluster 266: 555 samples\n",
      "  Cluster 267: 381 samples\n",
      "  Cluster 268: 243 samples\n",
      "  Cluster 269: 212 samples\n",
      "  Cluster 270: 141 samples\n",
      "  Cluster 271: 339 samples\n",
      "  Cluster 272: 1376 samples\n",
      "  Cluster 273: 144 samples\n",
      "  Cluster 274: 96 samples\n",
      "  Cluster 275: 192 samples\n",
      "  Cluster 276: 430 samples\n",
      "  Cluster 277: 97 samples\n",
      "  Cluster 278: 166 samples\n",
      "  Cluster 279: 545 samples\n",
      "  Cluster 280: 1062 samples\n",
      "  Cluster 281: 261 samples\n",
      "  Cluster 282: 142 samples\n",
      "  Cluster 283: 215 samples\n",
      "  Cluster 284: 477 samples\n",
      "  Cluster 285: 265 samples\n",
      "  Cluster 286: 167 samples\n",
      "  Cluster 287: 261 samples\n",
      "  Cluster 288: 386 samples\n",
      "  Cluster 289: 600 samples\n",
      "  Cluster 290: 213 samples\n",
      "  Cluster 291: 309 samples\n",
      "  Cluster 292: 338 samples\n",
      "  Cluster 293: 280 samples\n",
      "  Cluster 294: 119 samples\n",
      "  Cluster 295: 286 samples\n",
      "  Cluster 296: 907 samples\n",
      "  Cluster 297: 165 samples\n",
      "  Cluster 298: 189 samples\n",
      "  Cluster 299: 455 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell: Clustering with faiss-gpu\n",
    "import faiss\n",
    "import numpy as np\n",
    "import gc\n",
    "batch_size= 244034\n",
    "n_points, d = features.shape\n",
    "print(f\"Number of points: {n_points}, Dimension: {d}\")\n",
    "# n_points = 12201748\n",
    "print(\"Clustering with faiss-gpu...\")\n",
    "# Set number of clusters (e.g., same logic as before)\n",
    "n_clusters = min(max(NUM_SAMPLES // 10, 10), 300)  # Between 10-300 clusters\n",
    "print(f\"Using {n_clusters} clusters\")\n",
    "\n",
    "# Initialize faiss KMeans (GPU)\n",
    "ngpu= faiss.get_num_gpus()          \n",
    "res = faiss.StandardGpuResources() \n",
    "kmeans = faiss.Kmeans(d=features.shape[1], k=n_clusters, gpu=True, niter=50, verbose=True, seed=5, max_points_per_centroid=2000000)\n",
    "\n",
    "# Train KMeans\n",
    "kmeans.train(features)\n",
    "\n",
    "cpu_centroids = faiss.IndexFlatL2(d)\n",
    "cpu_centroids.add(kmeans.centroids)\n",
    "\n",
    "gpu_centroids = faiss.index_cpu_to_all_gpus(cpu_centroids)  # two-device copy\n",
    "\n",
    "\n",
    "# Assign clusters\n",
    "labels = np.empty(len(features), dtype=np.int32)\n",
    "for start in range(0, len(features), batch_size):\n",
    "    end = min(start + batch_size, len(features))\n",
    "    batch = np.ascontiguousarray(features[start:end])\n",
    "    _, I = gpu_centroids.search(batch, 1)\n",
    "    labels[start:end] = I.ravel()\n",
    "\n",
    "df_complete['faiss_cluster'] = labels\n",
    "print(f\"Cluster assignment complete. Cluster counts:\")\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  Cluster {u}: {c} samples\")\n",
    "\n",
    "# Clean up GPU memory\n",
    "del features, kmeans, res\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6ac7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.to_csv(\"./datasets/cysdb_complete_with_clusters.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
