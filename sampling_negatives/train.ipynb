{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b236b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4090\n",
      "GPU Memory: 25.3 GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and device setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "import esm\n",
    "from descriptastorus.descriptors import rdNormalizedDescriptors\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "# Device setup with memory management\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "# Memory monitoring function\n",
    "def check_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "        gpu_max = torch.cuda.max_memory_allocated() / 1e9\n",
    "        print(f\"GPU Memory: {gpu_mem:.2f} GB / {gpu_max:.2f} GB max\")\n",
    "    \n",
    "    cpu_mem = psutil.virtual_memory()\n",
    "    print(f\"CPU Memory: {cpu_mem.percent:.1f}% used\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c150bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading combined dataset...\n",
      "Dataset composition:\n",
      "  Positives: 49,511\n",
      "  Negatives: 49,511\n",
      "  Total: 99,022\n",
      "  Balance: 0.500\n",
      "GPU Memory: 0.00 GB / 0.00 GB max\n",
      "CPU Memory: 8.7% used\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load combined dataset\n",
    "print(\"Loading combined dataset...\")\n",
    "positives = pd.read_csv('../datasets/cysdb_positives.csv')\n",
    "sampled_negatives = pd.read_csv('sampled_negatives.csv')\n",
    "\n",
    "# Combine datasets\n",
    "combined_df = pd.concat([positives, sampled_negatives], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset composition:\")\n",
    "print(f\"  Positives: {len(positives):,}\")\n",
    "print(f\"  Negatives: {len(sampled_negatives):,}\")\n",
    "print(f\"  Total: {len(combined_df):,}\")\n",
    "print(f\"  Balance: {combined_df['Activity'].mean():.3f}\")\n",
    "\n",
    "check_memory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8c6e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up ESM-2 33-layer model...\n",
      "GPU Memory: 0.00 GB / 0.00 GB max\n",
      "CPU Memory: 8.8% used\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 23.52 GiB of which 16.75 MiB is free. Process 2115792 has 22.72 GiB memory in use. Including non-PyTorch memory, this process has 688.00 MiB memory in use. Of the allocated memory 282.40 MiB is allocated by PyTorch, and 21.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load ESM model\u001b[39;00m\n\u001b[32m     12\u001b[39m model_esm, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m model_esm = \u001b[43mmodel_esm\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m batch_converter = alphabet.get_batch_converter()\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mESM-2 33-layer model loaded successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/miniconda3/envs/chemmap/lib/python3.11/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/miniconda3/envs/chemmap/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/miniconda3/envs/chemmap/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/miniconda3/envs/chemmap/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/miniconda3/envs/chemmap/lib/python3.11/site-packages/torch/nn/modules/module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/miniconda3/envs/chemmap/lib/python3.11/site-packages/torch/nn/modules/module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 23.52 GiB of which 16.75 MiB is free. Process 2115792 has 22.72 GiB memory in use. Including non-PyTorch memory, this process has 688.00 MiB memory in use. Of the allocated memory 282.40 MiB is allocated by PyTorch, and 21.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Cell 3: Protein embeddings via ESM2-t33 - Fixed approach\n",
    "print(\"Setting up ESM-2 33-layer model...\")\n",
    "\n",
    "# Clear GPU memory first\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    gc.collect()\n",
    "    check_memory()\n",
    "\n",
    "# Load ESM model\n",
    "model_esm, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "model_esm = model_esm.eval().to(device)\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "print(\"ESM-2 33-layer model loaded successfully\")\n",
    "\n",
    "# Get unique proteins from the combined dataset\n",
    "unique_proteins = combined_df[['Entry', 'Sequence']].drop_duplicates()\n",
    "print(f\"Unique proteins to embed: {len(unique_proteins):,}\")\n",
    "\n",
    "# Embedding parameters\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4  # Start with small batch\n",
    "\n",
    "# Storage for embeddings\n",
    "protein_embeddings = {}\n",
    "protein_sequences = {}\n",
    "\n",
    "# Process proteins in batches\n",
    "protein_list = unique_proteins.values.tolist()\n",
    "print(\"Generating protein embeddings...\")\n",
    "\n",
    "for i in tqdm(range(0, len(protein_list), BATCH_SIZE), desc=\"ESM-2 batches\"):\n",
    "    batch = protein_list[i:i + BATCH_SIZE]\n",
    "    \n",
    "    # Prepare batch\n",
    "    batch_data = []\n",
    "    batch_entries = []\n",
    "    \n",
    "    for entry, seq in batch:\n",
    "        seq_trunc = seq if len(seq) <= MAX_LEN else seq[:MAX_LEN]\n",
    "        batch_data.append((entry, seq_trunc))\n",
    "        batch_entries.append(entry)\n",
    "    \n",
    "    try:\n",
    "        # Convert batch\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(batch_data)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        \n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            results = model_esm(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "            representations = results['representations'][33]\n",
    "        \n",
    "        # Store embeddings (mean pooling)\n",
    "        for j, entry in enumerate(batch_entries):\n",
    "            seq_len = len(batch_strs[j])\n",
    "            rep = representations[j, 1:seq_len+1]  # Remove CLS token\n",
    "            protein_embeddings[entry] = rep.mean(0).cpu().numpy().astype(np.float32)\n",
    "            protein_sequences[entry] = batch_strs[j]\n",
    "        \n",
    "        # Cleanup\n",
    "        del batch_tokens, results, representations\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"OOM at batch {i//BATCH_SIZE + 1}, reducing batch size...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Process one by one\n",
    "            for entry, seq in batch:\n",
    "                seq_trunc = seq if len(seq) <= MAX_LEN else seq[:MAX_LEN]\n",
    "                single_data = [(entry, seq_trunc)]\n",
    "                \n",
    "                _, single_strs, single_tokens = batch_converter(single_data)\n",
    "                single_tokens = single_tokens.to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    single_results = model_esm(single_tokens, repr_layers=[33], return_contacts=False)\n",
    "                    single_rep = single_results['representations'][33]\n",
    "                \n",
    "                seq_len = len(single_strs[0])\n",
    "                rep = single_rep[0, 1:seq_len+1]\n",
    "                protein_embeddings[entry] = rep.mean(0).cpu().numpy().astype(np.float32)\n",
    "                protein_sequences[entry] = single_strs[0]\n",
    "                \n",
    "                del single_tokens, single_results, single_rep\n",
    "                torch.cuda.empty_cache()\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "print(f\"Generated embeddings for {len(protein_embeddings)} proteins\")\n",
    "\n",
    "# Create mapping compatible with the training pipeline\n",
    "prot_index = {}\n",
    "mean_seq = {}\n",
    "\n",
    "for i, (entry, seq) in enumerate(unique_proteins.values):\n",
    "    if entry in protein_embeddings:\n",
    "        label = f'P{i}'\n",
    "        prot_index[label] = seq\n",
    "        mean_seq[label] = protein_embeddings[entry]\n",
    "\n",
    "print(f\"Created mappings for {len(mean_seq)} proteins\")\n",
    "\n",
    "# Free ESM model memory\n",
    "del model_esm, alphabet, batch_converter\n",
    "del protein_embeddings, protein_sequences\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"ESM model freed, ready for training\")\n",
    "check_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Molecule descriptors via RDKit\n",
    "print(\"Computing molecular descriptors...\")\n",
    "gen = rdNormalizedDescriptors.RDKit2DNormalized()\n",
    "mol_index, mol_feats = {}, {}\n",
    "smiles_list = combined_df['SMILES'].unique().tolist()\n",
    "\n",
    "for i, smi in enumerate(tqdm(smiles_list, desc=\"RDKit descriptors\")):\n",
    "    label = f'M{i}'\n",
    "    mol_index[label] = smi\n",
    "    try:\n",
    "        desc = gen.process(smiles=smi)\n",
    "        if desc is not None and len(desc) > 1:\n",
    "            mol_feats[label] = np.array(desc[1:], dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {smi}: {e}\")\n",
    "\n",
    "print(f\"Generated features for {len(mol_feats)} molecules\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1372876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Map dataset to indices\n",
    "print(\"Mapping dataset to feature indices...\")\n",
    "prot_map = {seq: pid for pid, seq in prot_index.items()}\n",
    "mol_map = {smi: mid for mid, smi in mol_index.items()}\n",
    "\n",
    "combined_df['P_index'] = combined_df['Sequence'].map(prot_map)\n",
    "combined_df['M_index'] = combined_df['SMILES'].map(mol_map)\n",
    "\n",
    "# Filter out any pairs without valid mappings\n",
    "valid_pairs = combined_df.dropna(subset=['P_index', 'M_index']).copy()\n",
    "print(f\"Valid pairs after mapping: {len(valid_pairs):,}\")\n",
    "\n",
    "pair_indices = list(valid_pairs[['P_index','M_index']].itertuples(index=False, name=None))\n",
    "y = valid_pairs['Activity'].values.astype(np.float32)\n",
    "\n",
    "print(f\"Final dataset: {len(y)} pairs, {y.mean():.3f} positive ratio\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3818c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: 5-Fold Cross-Validation Setup\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"Setting up 5-fold cross-validation...\")\n",
    "\n",
    "# Create 5-fold CV with stratification\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_indices = list(range(len(pair_indices)))\n",
    "\n",
    "# Store CV results\n",
    "cv_results = {\n",
    "    'fold_auprcs': [],\n",
    "    'fold_accs': [],\n",
    "    'fold_mccs': [],\n",
    "    'fold_histories': []\n",
    "}\n",
    "\n",
    "print(f\"Total samples: {len(y):,}\")\n",
    "print(f\"Positive ratio: {y.mean():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee874097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Dataset & DataLoader definitions (same as before)\n",
    "class ProtMolDataset(Dataset):\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        pi, mi = pair_indices[self.indices[ix]]\n",
    "        return mean_seq[pi], mol_feats[mi], y[self.indices[ix]]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    prots = torch.tensor([p for p, _, _ in batch], dtype=torch.float32)\n",
    "    mols = torch.tensor([m for _, m, _ in batch], dtype=torch.float32)\n",
    "    tgts = torch.tensor([t for _, _, t in batch], dtype=torch.float32)\n",
    "    return prots.to(device), mols.to(device), tgts.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bdd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Model definition (same as before)\n",
    "class MolProteinCrossAttention(nn.Module):\n",
    "    def __init__(self, prot_dim, mol_dim, emb_dim=256, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Protein and molecule projection layers\n",
    "        self.prot_proj = nn.Sequential(\n",
    "            nn.Linear(prot_dim, emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(emb_dim, emb_dim)\n",
    "        )\n",
    "        \n",
    "        self.mol_proj = nn.Sequential(\n",
    "            nn.Linear(mol_dim, emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(emb_dim, emb_dim)\n",
    "        )\n",
    "        \n",
    "        # Cross-attention mechanism\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=emb_dim,\n",
    "            num_heads=8,\n",
    "            dropout=dropout_rate,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Final prediction layers\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(emb_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0.01)\n",
    "    \n",
    "    def forward(self, x_prot, x_mol):\n",
    "        # Project to common embedding space\n",
    "        prot_emb = self.prot_proj(x_prot)  # [batch, emb_dim]\n",
    "        mol_emb = self.mol_proj(x_mol)     # [batch, emb_dim]\n",
    "        \n",
    "        # Add sequence dimension for attention\n",
    "        prot_seq = prot_emb.unsqueeze(1)   # [batch, 1, emb_dim]\n",
    "        mol_seq = mol_emb.unsqueeze(1)     # [batch, 1, emb_dim]\n",
    "        \n",
    "        # Cross-attention: protein queries molecule\n",
    "        prot_attended, _ = self.cross_attn(prot_seq, mol_seq, mol_seq)\n",
    "        prot_attended = prot_attended.squeeze(1)  # [batch, emb_dim]\n",
    "        \n",
    "        # Combine attended protein with original molecule\n",
    "        combined = torch.cat([prot_attended, mol_emb], dim=1)  # [batch, emb_dim*2]\n",
    "        \n",
    "        # Final prediction\n",
    "        output = self.predictor(combined)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "# Get dimensions from sample data\n",
    "PROT_DIM = len(list(mean_seq.values())[0])\n",
    "MOL_DIM = len(list(mol_feats.values())[0])\n",
    "\n",
    "print(f\"Model input dimensions: Protein={PROT_DIM}, Molecule={MOL_DIM}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2adc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: 5-Fold Cross-Validation Training\n",
    "def train_single_fold(train_idx, val_idx, fold_num):\n",
    "    \"\"\"Train model for a single fold\"\"\"\n",
    "    print(f\"\\n{'='*20} FOLD {fold_num} {'='*20}\")\n",
    "    \n",
    "    # Create data loaders for this fold\n",
    "    train_dataset = ProtMolDataset(train_idx)\n",
    "    val_dataset = ProtMolDataset(val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=256, \n",
    "        shuffle=True, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=512, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Fold {fold_num}: Train={len(train_idx):,}, Val={len(val_idx):,}\")\n",
    "    print(f\"Train balance: {y[train_idx].mean():.3f}, Val balance: {y[val_idx].mean():.3f}\")\n",
    "    \n",
    "    # Initialize fresh model for this fold\n",
    "    model = MolProteinCrossAttention(PROT_DIM, MOL_DIM).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=3)\n",
    "    \n",
    "    # Training tracking for this fold\n",
    "    best_auprc = 0.0\n",
    "    train_losses, val_auprcs = [], []\n",
    "    patience_counter = 0\n",
    "    max_patience = 8\n",
    "    \n",
    "    num_epochs = 50  # Increased epochs for better training\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for prot, mol, tgt in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(prot, mol)\n",
    "            loss = criterion(pred, tgt)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        all_preds, all_tgts = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for prot, mol, tgt in val_loader:\n",
    "                pred = model(prot, mol)\n",
    "                all_preds.append(pred.cpu())\n",
    "                all_tgts.append(tgt.cpu())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        preds = torch.cat(all_preds).numpy()\n",
    "        tgts = torch.cat(all_tgts).numpy()\n",
    "        \n",
    "        auprc = average_precision_score(tgts, preds)\n",
    "        acc = accuracy_score(tgts, preds > 0.5)\n",
    "        mcc = matthews_corrcoef(tgts, preds > 0.5)\n",
    "        \n",
    "        val_auprcs.append(auprc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(auprc)\n",
    "        \n",
    "        # Save best model for this fold\n",
    "        if auprc > best_auprc:\n",
    "            best_auprc = auprc\n",
    "            torch.save(model.state_dict(), f'best_model_fold_{fold_num}.pt')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Print progress every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"  Epoch {epoch:02d}: Loss {avg_train_loss:.4f}, AUPRC {auprc:.4f}, Acc {acc:.4f}, MCC {mcc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= max_patience:\n",
    "            print(f\"  Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # Final evaluation for this fold\n",
    "    model.load_state_dict(torch.load(f'best_model_fold_{fold_num}.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds, all_tgts = [], []\n",
    "    with torch.no_grad():\n",
    "        for prot, mol, tgt in val_loader:\n",
    "            pred = model(prot, mol)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_tgts.append(tgt.cpu())\n",
    "    \n",
    "    final_preds = torch.cat(all_preds).numpy()\n",
    "    final_tgts = torch.cat(all_tgts).numpy()\n",
    "    \n",
    "    fold_auprc = average_precision_score(final_tgts, final_preds)\n",
    "    fold_acc = accuracy_score(final_tgts, final_preds > 0.5)\n",
    "    fold_mcc = matthews_corrcoef(final_tgts, final_preds > 0.5)\n",
    "    \n",
    "    print(f\"Fold {fold_num} Results: AUPRC {fold_auprc:.4f}, Acc {fold_acc:.4f}, MCC {fold_mcc:.4f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return fold_auprc, fold_acc, fold_mcc, {'train_losses': train_losses, 'val_auprcs': val_auprcs}\n",
    "\n",
    "# Run 5-fold cross-validation\n",
    "print(\"Starting 5-fold cross-validation...\")\n",
    "\n",
    "for fold_num, (train_idx, val_idx) in enumerate(kfold.split(all_indices, y), 1):\n",
    "    fold_auprc, fold_acc, fold_mcc, fold_history = train_single_fold(train_idx, val_idx, fold_num)\n",
    "    \n",
    "    cv_results['fold_auprcs'].append(fold_auprc)\n",
    "    cv_results['fold_accs'].append(fold_acc)\n",
    "    cv_results['fold_mccs'].append(fold_mcc)\n",
    "    cv_results['fold_histories'].append(fold_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Cross-Validation Results Summary with Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "auprcs = cv_results['fold_auprcs']\n",
    "accs = cv_results['fold_accs']\n",
    "mccs = cv_results['fold_mccs']\n",
    "\n",
    "print(\"Per-fold results:\")\n",
    "for i, (auprc, acc, mcc) in enumerate(zip(auprcs, accs, mccs), 1):\n",
    "    print(f\"  Fold {i}: AUPRC {auprc:.4f}, Acc {acc:.4f}, MCC {mcc:.4f}\")\n",
    "\n",
    "print(f\"\\nMean ± Std:\")\n",
    "print(f\"  AUPRC: {np.mean(auprcs):.4f} ± {np.std(auprcs):.4f}\")\n",
    "print(f\"  Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "print(f\"  MCC: {np.mean(mccs):.4f} ± {np.std(mccs):.4f}\")\n",
    "\n",
    "# Create comprehensive plots\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Per-fold performance comparison\n",
    "plt.subplot(3, 3, 1)\n",
    "folds = range(1, 6)\n",
    "plt.bar(folds, auprcs, alpha=0.7, color='skyblue', edgecolor='navy')\n",
    "plt.axhline(y=np.mean(auprcs), color='red', linestyle='--', alpha=0.8, label=f'Mean: {np.mean(auprcs):.3f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('AUPRC')\n",
    "plt.title('AUPRC Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.bar(folds, accs, alpha=0.7, color='lightgreen', edgecolor='darkgreen')\n",
    "plt.axhline(y=np.mean(accs), color='red', linestyle='--', alpha=0.8, label=f'Mean: {np.mean(accs):.3f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.bar(folds, mccs, alpha=0.7, color='salmon', edgecolor='darkred')\n",
    "plt.axhline(y=np.mean(mccs), color='red', linestyle='--', alpha=0.8, label=f'Mean: {np.mean(mccs):.3f}')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('MCC')\n",
    "plt.title('MCC Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Training curves for each fold\n",
    "plt.subplot(3, 3, 4)\n",
    "for i, history in enumerate(cv_results['fold_histories']):\n",
    "    plt.plot(history['train_losses'], label=f'Fold {i+1}', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(3, 3, 5)\n",
    "for i, history in enumerate(cv_results['fold_histories']):\n",
    "    plt.plot(history['val_auprcs'], label=f'Fold {i+1}', alpha=0.7)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation AUPRC')\n",
    "plt.title('Validation AUPRC Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Performance distribution\n",
    "plt.subplot(3, 3, 6)\n",
    "metrics_data = {\n",
    "    'AUPRC': auprcs,\n",
    "    'Accuracy': accs,\n",
    "    'MCC': mccs\n",
    "}\n",
    "box_data = [auprcs, accs, mccs]\n",
    "plt.boxplot(box_data, labels=['AUPRC', 'Accuracy', 'MCC'])\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Combined metrics plot\n",
    "plt.subplot(3, 3, 7)\n",
    "x = np.arange(len(folds))\n",
    "width = 0.25\n",
    "plt.bar(x - width, auprcs, width, label='AUPRC', alpha=0.8)\n",
    "plt.bar(x, accs, width, label='Accuracy', alpha=0.8)\n",
    "plt.bar(x + width, mccs, width, label='MCC', alpha=0.8)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('All Metrics by Fold')\n",
    "plt.xticks(x, [f'Fold {i}' for i in folds])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Performance vs Mean\n",
    "plt.subplot(3, 3, 8)\n",
    "metrics = ['AUPRC', 'Accuracy', 'MCC']\n",
    "means = [np.mean(auprcs), np.mean(accs), np.mean(mccs)]\n",
    "stds = [np.std(auprcs), np.std(accs), np.std(mccs)]\n",
    "plt.errorbar(metrics, means, yerr=stds, fmt='o-', capsize=5, capthick=2, markersize=8)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Mean Performance ± Std')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Best vs Worst fold comparison\n",
    "plt.subplot(3, 3, 9)\n",
    "best_fold = np.argmax(auprcs) + 1\n",
    "worst_fold = np.argmin(auprcs) + 1\n",
    "comparison_data = {\n",
    "    'AUPRC': [auprcs[best_fold-1], auprcs[worst_fold-1]],\n",
    "    'Accuracy': [accs[best_fold-1], accs[worst_fold-1]],\n",
    "    'MCC': [mccs[best_fold-1], mccs[worst_fold-1]]\n",
    "}\n",
    "x_pos = np.arange(len(metrics))\n",
    "plt.bar(x_pos - 0.2, [comparison_data['AUPRC'][0], comparison_data['Accuracy'][0], comparison_data['MCC'][0]], \n",
    "        0.4, label=f'Best (Fold {best_fold})', alpha=0.8)\n",
    "plt.bar(x_pos + 0.2, [comparison_data['AUPRC'][1], comparison_data['Accuracy'][1], comparison_data['MCC'][1]], \n",
    "        0.4, label=f'Worst (Fold {worst_fold})', alpha=0.8)\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Best vs Worst Fold')\n",
    "plt.xticks(x_pos, metrics)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_results_comprehensive.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Additional detailed training plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Individual fold training curves\n",
    "for i, history in enumerate(cv_results['fold_histories']):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    \n",
    "    if i < 5:  # We have 5 folds\n",
    "        ax = axes[row, col]\n",
    "        epochs = range(1, len(history['train_losses']) + 1)\n",
    "        \n",
    "        # Plot training loss and validation AUPRC\n",
    "        ax2 = ax.twinx()\n",
    "        \n",
    "        line1 = ax.plot(epochs, history['train_losses'], 'b-', label='Training Loss', alpha=0.7)\n",
    "        line2 = ax2.plot(epochs, history['val_auprcs'], 'r-', label='Validation AUPRC', alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Training Loss', color='b')\n",
    "        ax2.set_ylabel('Validation AUPRC', color='r')\n",
    "        ax.set_title(f'Fold {i+1} Training Progress')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Combined legend\n",
    "        lines = line1 + line2\n",
    "        labels = [l.get_label() for l in lines]\n",
    "        ax.legend(lines, labels, loc='center right')\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[1, 2].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('individual_fold_training.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics plot\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Correlation matrix of metrics\n",
    "metric_df = pd.DataFrame({\n",
    "    'AUPRC': auprcs,\n",
    "    'Accuracy': accs,\n",
    "    'MCC': mccs\n",
    "})\n",
    "correlation_matrix = metric_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=ax1)\n",
    "ax1.set_title('Metric Correlations Across Folds')\n",
    "\n",
    "# Performance variability\n",
    "cv_scores = [np.std(auprcs)/np.mean(auprcs), np.std(accs)/np.mean(accs), np.std(mccs)/np.mean(mccs)]\n",
    "ax2.bar(metrics, cv_scores, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "ax2.set_ylabel('Coefficient of Variation')\n",
    "ax2.set_title('Performance Variability (CV)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Fold ranking by AUPRC\n",
    "fold_rankings = np.argsort(auprcs)[::-1] + 1\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 5))\n",
    "ax3.bar(range(1, 6), np.sort(auprcs)[::-1], color=colors)\n",
    "ax3.set_xlabel('Rank')\n",
    "ax3.set_ylabel('AUPRC')\n",
    "ax3.set_title('Fold Ranking by AUPRC')\n",
    "ax3.set_xticks(range(1, 6))\n",
    "ax3.set_xticklabels([f'Fold {r}' for r in fold_rankings])\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Performance improvement over epochs (average)\n",
    "avg_train_losses = np.mean([hist['train_losses'] for hist in cv_results['fold_histories']], axis=0)\n",
    "avg_val_auprcs = np.mean([hist['val_auprcs'] for hist in cv_results['fold_histories']], axis=0)\n",
    "\n",
    "ax4_twin = ax4.twinx()\n",
    "epochs = range(1, len(avg_train_losses) + 1)\n",
    "ax4.plot(epochs, avg_train_losses, 'b-', label='Avg Training Loss')\n",
    "ax4_twin.plot(epochs, avg_val_auprcs, 'r-', label='Avg Validation AUPRC')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Training Loss', color='b')\n",
    "ax4_twin.set_ylabel('Validation AUPRC', color='r')\n",
    "ax4.set_title('Average Training Progress')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_analysis_detailed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save CV results\n",
    "torch.save(cv_results, 'cv_results.pt')\n",
    "\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"- best_model_fold_1.pt through best_model_fold_5.pt\")\n",
    "print(\"- cv_results.pt\")\n",
    "print(\"- cv_results_comprehensive.png\")\n",
    "print(\"- individual_fold_training.png\") \n",
    "print(\"- cv_analysis_detailed.png\")\n",
    "\n",
    "check_memory()\n",
    "print(\"\\n✅ 5-Fold Cross-Validation with comprehensive plotting complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
